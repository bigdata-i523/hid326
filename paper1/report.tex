\documentclass[sigconf]{acmart}

\usepackage{hyperref}

\usepackage{endfloat}
\renewcommand{\efloatseparator}{\mbox{}} % no new page between figures

\usepackage{booktabs} % For formal tables

\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain} % removes running headers

\begin{document}
\title{Bigdata in Clinical Trails}


\author{Mohan Mahendrakar}
\orcid{1234-5678-9012}
\affiliation{%
  \institution{Indiana University}
  \streetaddress{P.O. Box 1212}
  \city{Raleigh} 
  \state{North Carolina} 
  \postcode{43017-6221}
}
\email{mohan1.data@gmail.com}

% The default list of authors is too long for headers}
\renewcommand{\shortauthors}{B. Trovato et al.}


\begin{abstract}
The vast volumes of data collected across the clinical trials process offers pharma and biotech 
the opportunity to leverage the information.
ACM SIG Proceedings.
\end{abstract}

\keywords{Bigdata, Clinical, Trails, Healthcare, Phase I, Phase II, Phase III, Phase IV}


\maketitle

\section{Introduction}

After transforming customer-facing functions such as sales and marketing, big data is extending its reach to other parts of the enterprise. In research and development, for example, big data and analytics are being adopted across industries, including pharmaceuticals.

\section{Integrate all data}

Having data that are consistent, reliable, and well linked is one of the biggest challenges facing pharmaceutical clinical Trails. The ability to manage and integrate data generated at all phases of the value chain, from discovery to real-world use after regulatory approval, is a fundamental requirement to allow companies to derive maximum benefit from the technology trends. Data are the foundation upon which the value-adding analytics are built. Effective end-to-end data integration establishes an authoritative source for all pieces of information and accurately links disparate data regardless of the source—be it internal or external, proprietary or publicly available. Data integration also enables comprehensive searches for subsets of data based on the linkages established rather than on the information itself. “Smart” algorithms linking laboratory and clinical data, for example, could create automatic reports that identify related applications or compounds and raise red flags concerning safety or efficacy.

Implementing end-to-end data integration requires a number of capabilities, including trusted sources of data and documents, the ability to establish cross-linkages between elements, robust quality assurance, workflow management, and role-based access to ensure that specific data elements are visible only to those who are authorized to see it. Pharmaceutical companies generally avoid overhauling their entire data-integration system at once because of the logistical challenges and costs involved, although at least one global pharmaceutical enterprise has employed a “big bang” approach to remaking its clinical IT systems.

\section{Challenge}
Big pharma companies typically keep their cards close to the vest because it costs so much to develop a drug throughout its lifetime.  From discovery to prescription pad, a typical medication can take twelve years and \$4 billion to shepherd through its lifecycle, a significant investment that would be hard to recoup if everyone had the secret to the newest blockbuster pill, especially since only ten percent of drugs ever make it to market.

\begin{acks}

  The authors would like to thank 

\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 

\end{document}
